{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ClassificationModel - This problem uses the census income data-set from the Cal Univ of Irvine Machine Learning Repo. Data-set is extracted from the U.S. Census Bureau database. \n",
    "Using this dataset we will classify if a person has a salary if a person has a salary of greater than $50k. It is a binary classification.'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #contains logsoftmax function. log_softmax is used for classification problems eg >50k or <50k salary\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age', 'Workclass', 'fnlwgt', 'Education', 'Education-num', 'Marital-status', 'Occupation',\n",
    "        'Relationship', 'Race', 'Sex', 'CG', 'CL', 'HPW', 'Country', 'Salary']\n",
    "unwanted_cols = ['fnlwgt', 'Education', 'Relationship', 'CG', 'CL', 'Country'] # cols which are less useful to predict salary of >50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = pd.read_csv('datasets/adult_salary.csv', names = cols).drop(unwanted_cols, axis=1).replace(' ?', np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Workclass', 'Education-num', 'Marital-status', 'Occupation',\n",
       "       'Race', 'Sex', 'HPW'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_features = salary_data.drop('Salary', axis=1)\n",
    "salary_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Male', ' Female'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_features['Sex'].unique() # the unique values of the sex column are string values but NN function better with numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder() # preprocess the data to convert them to numeric form.\n",
    "salary_features[['Sex']] = salary_features[['Sex']].apply(le.fit_transform) # le.fit_transform function to convert all values to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = ['Workclass', 'Marital-status', 'Occupation', 'Race'] # leftover columns with string data which contains more than 2 values\n",
    "salary_features = pd.get_dummies(salary_features, columns = ohe_cols) # convert column data to one-hot-encoded form so that categorical data can be more expressive (binary values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalable_cols = ['Age', 'Education-num', 'HPW'] # store numerical data in variable to prepare for converting to standardized data\n",
    "salary_features[scalable_cols] = preprocessing.scale(salary_features[scalable_cols]) # preprocess the column to standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_target = salary_data[['Salary']] # store the Y values, which will be the target values (salary), in a target variable\n",
    "salary_target = salary_target.apply(le.fit_transform) # le.fit_transform function to convert all values to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the training set is so large we use 80% for training and 20% for testing how our model performs\n",
    "X_train, x_test, Y_train, y_test = train_test_split(salary_features, \n",
    "                                                    salary_target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put training and test data into PyTorch Tensors\n",
    "Xtrain_ = torch.from_numpy(X_train.values).float()\n",
    "Xtest_ = torch.from_numpy(x_test.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24574, 37])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape our data to match the y-label format that our loss function requires (in this case: NLL) \n",
    "Ytrain_ = torch.from_numpy(Y_train.values).view(1, -1)[0].type(torch.LongTensor) # reshape to 1-D tensor with all data in 1 row\n",
    "Ytest_ = torch.from_numpy(y_test.values).view(1, -1)[0].type(torch.LongTensor) # reshape to 1-D tensor with all data in 1 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 37\n",
    "output_size = 2 # >50k or <50k\n",
    "hidden_size = 10 # figure this out as you run several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): # build custom NN modules by subclassing nn.Module class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # call the super class to initialize the NN before adding in the layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)       \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)        \n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) # three linear fully-connected layers\n",
    "        \n",
    "    def forward(self, x): # override the forward function to feed the X data into the fully-connected linear layers\n",
    "        x = F.relu(self.fc1(x)) # Apply the sigmoid activation function to the first layer\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # last layer is a linear layer with no activation\n",
    "        \n",
    "        return F.log_softmax(x, dim=-1) # feed X output from 3rd layer into log_softmax function. log_softmax is used for classification problems eg >50k or <50k salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net() # instantiate model of the network by calling Net() class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters()) # use the adam optimizer which is an adaptive learning rate optimzer which works very well in NNs and is very popular\n",
    "\n",
    "loss_fn = nn.NLLLoss() #set loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 100 (10%) train loss - 0.47 test loss - 0.48 accuracy - 0.7477\n",
      "epoch - 200 (20%) train loss - 0.39 test loss - 0.39 accuracy - 0.8005\n",
      "epoch - 300 (30%) train loss - 0.37 test loss - 0.38 accuracy - 0.8293\n",
      "epoch - 400 (40%) train loss - 0.37 test loss - 0.37 accuracy - 0.8320\n",
      "epoch - 500 (50%) train loss - 0.37 test loss - 0.37 accuracy - 0.8340\n",
      "epoch - 600 (60%) train loss - 0.36 test loss - 0.37 accuracy - 0.8358\n",
      "epoch - 700 (70%) train loss - 0.36 test loss - 0.36 accuracy - 0.8371\n",
      "epoch - 800 (80%) train loss - 0.35 test loss - 0.36 accuracy - 0.8387\n",
      "epoch - 900 (90%) train loss - 0.35 test loss - 0.36 accuracy - 0.8385\n",
      "epoch - 1000 (100%) train loss - 0.35 test loss - 0.36 accuracy - 0.8390\n"
     ]
    }
   ],
   "source": [
    "# set training data\n",
    "epoch_data = []\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    Ypred = model(Xtrain_)\n",
    "    \n",
    "    loss = loss_fn(Ypred, Ytrain_) # calc loss on the prediction\n",
    "    loss.backward() # perform backward pass to calc gradients\n",
    "    \n",
    "    optimizer.step() # update the params by applying grads\n",
    "    \n",
    "    Ypred_test = model(Xtest_) # 5 min 45 sec\n",
    "    loss_test = loss_fn(Ypred_test, Ytest_)\n",
    "    \n",
    "    _,pred = Ypred_test.data.max(1)\n",
    "    \n",
    "    accuracy = pred.eq(Ytest_.data).sum().item() / y_test.values.size\n",
    "    epoch_data.append([epoch, loss.data.item(), loss_test.data.item(), accuracy])\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch - %d (%d%%) train loss - %.2f test loss - %.2f accuracy - %.4f' \n",
    "              % (epoch, epoch/100 * 10, loss.data.item(), loss_test.data.item(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
