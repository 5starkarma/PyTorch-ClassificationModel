{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Salary Binary Classification\nThis problem uses the census income data-set from the Cal Univ of Irvine Machine Learning Repo. Data-set is extracted from the U.S. Census Bureau database. Using this dataset we will classify if a person has a salary if a person has a salary of greater than $50k. It is strictly a binary classification."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# kaggle/python Docker image: https://github.com/kaggle/docker-python\nimport numpy as np \nimport pandas as pd \n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":114,"outputs":[{"output_type":"stream","text":"/kaggle/input/adult-census-income/adult.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\n    'Age', 'Workclass', 'fnlwgt', 'Education', 'Education-num', \n    'Marital-status', 'Occupation', 'Relationship', 'Race', 'Sex', \n    'CG', 'CL', 'HPW', 'Country', 'Salary'\n]\nunwanted_cols = [\n    'fnlwgt', 'Education', 'Relationship', 'CG', 'CL', 'Country'\n]","execution_count":115,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read data. Drop unwanted columns. Replace '?' with 'nan'. Drop na."},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_data = pd.read_csv('../input/adult-census-income/adult.csv', names=cols, header=0).drop(unwanted_cols, axis=1).replace('?', np.nan).dropna()\nsalary_features = salary_data.drop('Salary', axis=1)","execution_count":116,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Convert data to numeric form (0 or 1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder = preprocessing.LabelEncoder()\n\n# salary_features[['Sex']] = salary_features[['Sex']].apply(label_encoder.fit_transform)\nsalary_target = salary_data[['Salary']].apply(label_encoder.fit_transform)","execution_count":117,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply one-hot-encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_cols = ['Workclass', 'Marital-status', 'Occupation', 'Race', 'Sex']\nsalary_features = pd.get_dummies(salary_features, columns=ohe_cols)","execution_count":118,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalize numerical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"scalable_cols = ['Age', 'Education-num', 'HPW']\nsalary_features[scalable_cols] = preprocessing.scale(salary_features[scalable_cols])","execution_count":119,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split into train and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, x_test, Y_train, y_test = train_test_split(\n    salary_features,               \n    salary_target,\n    test_size=0.20,\n    random_state=0\n)","execution_count":120,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and test data into PyTorch Tensors"},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain_ = torch.from_numpy(X_train.values).float()\nXtest_ = torch.from_numpy(x_test.values).float()\nXtrain_.shape","execution_count":121,"outputs":[{"output_type":"execute_result","execution_count":121,"data":{"text/plain":"torch.Size([24574, 38])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Reshape our data to match the y-label format that our loss function requires"},{"metadata":{"trusted":true},"cell_type":"code","source":"Ytrain_ = torch.from_numpy(Y_train.values).view(1, -1)[0].type(torch.LongTensor) # reshape to 1-D tensor with all data in 1 row\nYtest_ = torch.from_numpy(y_test.values).view(1, -1)[0].type(torch.LongTensor)\nYtrain_.type()","execution_count":122,"outputs":[{"output_type":"execute_result","execution_count":122,"data":{"text/plain":"'torch.LongTensor'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Create NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(38, 32)       \n        self.fc2 = nn.Linear(32, 32)   \n        self.fc3 = nn.Linear(32, 2)\n        \n    def forward(self, x): \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        \n        return F.log_softmax(x, dim=-1)","execution_count":123,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net()\noptimizer = optim.Adam(model.parameters())\nloss_fn = nn.CrossEntropyLoss() ","execution_count":124,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch_data = []\nepochs = 1000\n\nfor epoch in range(1, epochs + 1):\n    optimizer.zero_grad()\n    \n    Ypred = model(Xtrain_)\n    \n    loss = loss_fn(Ypred, Ytrain_)\n    loss.backward() \n    \n    optimizer.step()\n    \n    Ypred_test = model(Xtest_)\n    loss_test = loss_fn(Ypred_test, Ytest_)\n    \n    _,pred = Ypred_test.data.max(1)\n    \n    accuracy = pred.eq(Ytest_.data).sum().item() / y_test.values.size\n    epoch_data.append([epoch, loss.data.item(), loss_test.data.item(), accuracy])\n    \n    if epoch % 100 == 0:\n        print(f'epoch - {epoch} ({epoch/100 * 10}%) train loss - {loss.data.item():.4f} test loss - {loss_test.data.item():.4f} accuracy - {accuracy:.4f}')","execution_count":125,"outputs":[{"output_type":"stream","text":"epoch - 100 (10.0%) train loss - 0.5295 test loss - 0.5260 accuracy - 0.7523\nepoch - 200 (20.0%) train loss - 0.3700 test loss - 0.3651 accuracy - 0.8322\nepoch - 300 (30.0%) train loss - 0.3582 test loss - 0.3550 accuracy - 0.8366\nepoch - 400 (40.0%) train loss - 0.3534 test loss - 0.3521 accuracy - 0.8364\nepoch - 500 (50.0%) train loss - 0.3499 test loss - 0.3492 accuracy - 0.8387\nepoch - 600 (60.0%) train loss - 0.3473 test loss - 0.3486 accuracy - 0.8410\nepoch - 700 (70.0%) train loss - 0.3459 test loss - 0.3484 accuracy - 0.8392\nepoch - 800 (80.0%) train loss - 0.3449 test loss - 0.3486 accuracy - 0.8392\nepoch - 900 (90.0%) train loss - 0.3438 test loss - 0.3481 accuracy - 0.8403\nepoch - 1000 (100.0%) train loss - 0.3431 test loss - 0.3483 accuracy - 0.8390\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}