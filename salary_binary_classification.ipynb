{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Salary Binary Classification\nThis problem uses the census income data-set from the Cal Univ of Irvine Machine Learning Repo. Data-set is extracted from the U.S. Census Bureau database. Using this dataset we will classify if a person has a salary if a person has a salary of greater than $50k. It is strictly a binary classification.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# kaggle/python Docker image: https://github.com/kaggle/docker-python\nimport numpy as np \nimport pandas as pd \n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\n    'Age', 'Workclass', 'fnlwgt', 'Education', 'Education-num', \n    'Marital-status', 'Occupation', 'Relationship', 'Race', 'Sex', \n    'CG', 'CL', 'HPW', 'Country', 'Salary'\n]\nunwanted_cols = [\n    'fnlwgt', 'Education', 'Relationship', 'CG', 'CL', 'Country'\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read data. Drop unwanted columns. Replace '?' with 'nan'. Drop na.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_data = pd.read_csv('../input/adult-census-income/adult.csv', names=cols, header=0).drop(unwanted_cols, axis=1).replace('?', np.nan).dropna()\nsalary_features = salary_data.drop('Salary', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert data to numeric form (0 or 1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder = preprocessing.LabelEncoder()\n\n# salary_features[['Sex']] = salary_features[['Sex']].apply(label_encoder.fit_transform)\nsalary_target = salary_data[['Salary']].apply(label_encoder.fit_transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply one-hot-encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_cols = ['Workclass', 'Marital-status', 'Occupation', 'Race', 'Sex']\nsalary_features = pd.get_dummies(salary_features, columns=ohe_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalize numerical data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scalable_cols = ['Age', 'Education-num', 'HPW']\nsalary_features[scalable_cols] = preprocessing.scale(salary_features[scalable_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split into train and test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, x_test, Y_train, y_test = train_test_split(\n    salary_features,               \n    salary_target,\n    test_size=0.20,\n    random_state=0\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and test data into PyTorch Tensors","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain_ = torch.from_numpy(X_train.values).float()\nXtest_ = torch.from_numpy(x_test.values).float()\nXtrain_.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reshape our data to match the y-label format that our loss function requires","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Ytrain_ = torch.from_numpy(Y_train.values).view(1, -1)[0].type(torch.LongTensor) # reshape to 1-D tensor with all data in 1 row\nYtest_ = torch.from_numpy(y_test.values).view(1, -1)[0].type(torch.LongTensor)\nYtrain_.type()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create NN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(38, 32)       \n        self.fc2 = nn.Linear(32, 32)   \n        self.fc3 = nn.Linear(32, 2)\n        \n    def forward(self, x): \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        \n        return F.log_softmax(x, dim=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net()\noptimizer = optim.Adam(model.parameters())\nloss_fn = nn.CrossEntropyLoss() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch_data = []\nepochs = 1000\n\nfor epoch in range(1, epochs + 1):\n    optimizer.zero_grad()\n    \n    Ypred = model(Xtrain_)\n    \n    loss = loss_fn(Ypred, Ytrain_)\n    loss.backward() \n    \n    optimizer.step()\n    \n    Ypred_test = model(Xtest_)\n    loss_test = loss_fn(Ypred_test, Ytest_)\n    \n    _,pred = Ypred_test.data.max(1)\n    \n    accuracy = pred.eq(Ytest_.data).sum().item() / y_test.values.size\n    epoch_data.append([epoch, loss.data.item(), loss_test.data.item(), accuracy])\n    \n    if epoch % 100 == 0:\n        print(f'epoch - {epoch} ({epoch/100 * 10}%) train loss - {loss.data.item():.4f} test loss - {loss_test.data.item():.4f} accuracy - {accuracy:.4f}')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}